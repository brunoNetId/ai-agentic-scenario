quarkus.log.category.dev.ai4j.openai4j.level=DEBUG
quarkus.log.category.io.vertx.core.level=ERROR

# Assigned port to avoid conflicts with other systems
camel.server.port=8080

camel.server.enabled=true
camel.server.staticEnabled=true

# Default LLM URL
llm.url=localhost:11434

# Proxy LLM URL (to capture tool calls)
ollama.llm.url=localhost:11400

